[🏠 Главная](../../README.md) → [☸️ Container-Orchestration](../../README.md#-container-orchestration) → [🔄 K-09-Жизненный-цикл-приложений](../../README.md#-k-09-жизненный-цикл-приложений)

---

# 📈K-09-10-Autoscaling-Benefits
>Преимущества автомасштабирования в Kubernetes: экономия средств, доступность, эффективное использование ресурсов, эластичность, отказоустойчивость, механизмы масштабирования кластера и PODs

---

<details>
<summary><b>💰Введение: преимущества автомасштабирования</b></summary>

---

## О чем эта лекция

Привет, давай поговорим о тех преимуществах, которые нам дает автомасштабирование. Их немало, но внезапно на первом месте я поставлю экономию средств.

Наш приоритет - это всегда отличный пользовательский опыт. Наши юзеры будут нам благодарны, если всегда смогут обратиться к нашей услуге и не почувствуют задержек в работе с ней.

---

## Проблема избыточного резервирования

Здесь появляется соблазн взять ресурсов с большим запасом, тем самым произвести избыточное резервирование, чтобы быть уверенным, что у пользователей все будет хорошо.

На самом деле это хорошо у них будет только пока не возникнет какого-то пика посещаемости ресурса, а наша компания, которая платит за ресурсы, но большую часть времени их не использует, будет вынуждена нести лишние траты.

### Схема проблемы избыточного резервирования

```
┌─────────────────────────────────────────────────────────┐
│  Избыточное резервирование                              │
│  ┌──────────────────────────────────────────────────┐   │
│  │                                                   │   │
│  │  Ресурсы: 100% (всегда)                          │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Использование: 30% (среднее)                │ │   │
│  │  │  Простой: 70% (потеря денег)                 │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  ❌ Платим за неиспользуемые ресурсы             │   │
│  │  ❌ При пике все равно может не хватить         │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Решение: автомасштабирование

Автомасштабирование помогает предотвратить потери, динамически регулируя ресурсы в зависимости от текущего спроса. Этим же улучшает опыт пользователей, поддерживая приложение в оптимальном состоянии.

### Схема работы автомасштабирования

```
┌─────────────────────────────────────────────────────────┐
│  Автомасштабирование                                    │
│  ┌──────────────────────────────────────────────────┐   │
│  │                                                   │   │
│  │  Низкая нагрузка                                 │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Ресурсы: 30%                               │ │   │
│  │  │  Использование: 30%                          │ │   │
│  │  │  ✅ Оптимально                              │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  Высокая нагрузка (пик)                          │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Ресурсы: 100% (автоматически увеличены)     │ │   │
│  │  │  Использование: 95%                           │ │   │
│  │  │  ✅ Справляется с нагрузкой                  │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  ✅ Платим только за используемые ресурсы        │   │
│  │  ✅ Автоматическая адаптация к нагрузке          │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Критерии масштабирования

В автоматическом масштабировании у Kubernetes много разных интересных вещей, поскольку в Kubernetes присутствует множество разных компонентов и механизмов, и мы должны организовать оптимальную производительность для всех частей кластера.

Таким образом, наша задача - выделить именно столько ресурсов, которые позволят приложениям в наших PODs работать соответствия установленными нами критериями.

Этими критериями могут быть приняты CPU индексы производительности или какие-то другие KPI и метрики.

---

</details>

<details>
<summary><b>🎯Преимущества автомасштабирования</b></summary>

---

## 1. Экономия средств 💰

**На первом месте - экономия средств.**

Автомасштабирование позволяет платить только за используемые ресурсы, избегая избыточного резервирования и лишних трат.

---

## 2. Доступность приложения 🌐

Во-первых, доступность приложения. Автоматическое масштабирование гарантирует, что наше приложение будет справляться с различными рабочими нагрузками без проблем.

Представь себе внезапный всплеск покупателей во время распродажи или запуска нового продукта. Мы хотим, чтобы этот наплыв оказал минимальное влияние на пользователей.

Поэтому автомасштабирование - это механизм, который автоматически изменяет ресурсы приложения, гарантируя нашим клиентам бесперебойную работу.

И это также означает, что при падении спроса система будет смасштабирована вниз, то есть уменьшена. Таким образом мы поддерживаем ресурсы в лучшем для работы состоянии.

### Схема адаптации к нагрузке

```
┌─────────────────────────────────────────────────────────┐
│  Нормальная нагрузка                                    │
│  ┌──────────────────────────────────────────────────┐   │
│  │  PODs: 3 реплики                                │   │
│  │  Ресурсы: 60%                                    │   │
│  │  ✅ Стабильная работа                           │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼ (всплеск трафика)
┌─────────────────────────────────────────────────────────┐
│  Высокая нагрузка                                       │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Автомасштабирование обнаруживает рост нагрузки   │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  PODs: 3 → 10 реплик (автоматически)        │ │   │
│  │  │  Ресурсы: 60% → 95%                          │ │   │
│  │  │  ✅ Справляется с нагрузкой                  │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼ (нагрузка падает)
┌─────────────────────────────────────────────────────────┐
│  Низкая нагрузка                                         │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Автомасштабирование уменьшает ресурсы            │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  PODs: 10 → 3 реплики (автоматически)       │ │   │
│  │  │  Ресурсы: 95% → 40%                          │ │   │
│  │  │  ✅ Экономия ресурсов                         │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## 3. Эффективное использование ресурсов ⚡

Другими словами, производим эффективное и действенное управление ресурсами, что опять же ведет к экономии затрат.

Что касается эффективного использования, думаю ты видел, как система выходит из строя из-за нехватки ресурсов, и точно также бывает обидно, когда на мощном сервере крутится минимум приложений, совершенно не реализуя потенциал железа.

Именно в этом заключается суть автомасштабирования - снижение или увеличение мощности в зависимости от реальных потребностей клиента.

Все дело в поиске правильного баланса - не слишком много и не слишком мало. Нам нужна золотая середина, когда все достойно работает, но нет простаивающих мощностей.

### Схема эффективного использования

```
┌─────────────────────────────────────────────────────────┐
│  Без автомасштабирования                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Сервер: 100% мощности                           │   │
│  │  Использование: 20%                              │   │
│  │  Простой: 80%                                    │   │
│  │  ❌ Неэффективно                                 │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  С автомасштабированием                                  │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Ресурсы: 20-100% (динамически)                  │   │
│  │  Использование: 80-95%                            │   │
│  │  Простой: 5-20%                                  │   │
│  │  ✅ Оптимально                                   │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## 4. Эластичность 🔄

Эти мы подходим к следующему понятию, которое воплощает в себе автомасштабирование, и это эластичность.

Эластичность - это причина, почему так популярны облачные решения с их политикой оплаты за потребление.

Приложение, запущенное в Kubernetes, сами по себе эластичный, так как они распределены по PODs, и мы можем эластично добавлять и удалять их экземпляры по мере необходимости.

То есть увеличивать, когда нам нужна дополнительная мощность, и уменьшать, когда она пропадает. И это все можно сделать без ручного вмешательства.

Итак, эластичность позволяет нашим приложениям эффективно адаптироваться к непредсказуемым изменениям трафика.

---

## 5. Отказоустойчивость и восстановление 🛡️

Следующее преимущество - отказоустойчивость и восстановление.

Отказоустойчивость и восстановление являются двумя важнейшими элементами поддержания надежности приложений.

Автоматическое масштабирование помогает нашей системе противостоять сбоям, распределяя нагрузку и гарантируя, что в случае сбоя мы сможем либо быстро восстановиться, либо даже не заметим этого сбоя.

Таким образом, автоскейлер будет автоматически восстанавливать прерванные ресурсы, обеспечивая необходимую мощность.

### Схема отказоустойчивости

```
┌─────────────────────────────────────────────────────────┐
│  Нормальная работа                                       │
│  ┌──────────────────────────────────────────────────┐   │
│  │  POD 1: ✅ Running                               │   │
│  │  POD 2: ✅ Running                               │   │
│  │  POD 3: ✅ Running                               │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼ (POD 2 падает)
┌─────────────────────────────────────────────────────────┐
│  Сбой обнаружен                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │  POD 1: ✅ Running                               │   │
│  │  POD 2: ❌ Failed                                │   │
│  │  POD 3: ✅ Running                               │   │
│  │                                                   │   │
│  │  Автомасштабирование:                             │   │
│  │  - Обнаруживает сбой                              │   │
│  │  - Создает новый POD                              │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼ (автоматическое восстановление)
┌─────────────────────────────────────────────────────────┐
│  Восстановление                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │  POD 1: ✅ Running                               │   │
│  │  POD 2: ❌ (удален)                              │   │
│  │  POD 3: ✅ Running                               │   │
│  │  POD 4: ✅ Running (новый)                       │   │
│  │                                                   │   │
│  │  ✅ Система восстановлена автоматически          │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## 6. Бесперебойное управление нагрузкой ⚖️

Тут также можно упомянуть о бесперебойном управлении нагрузкой. Это больше относится к особенностям Kubernetes, тем не менее это очень тесно связано с масштабированием.

Я имею в виду, что по мере колебаний спроса выделяются дополнительные экземпляры, а Kubernetes их бесшовно выкатывает.

---

## 7. Простота реализации 🛠️

Напоследок я хочу упомянуть о сложности реализации.

Управление автомасштабированием Kubernetes очень простое и эффективное:

- **Простое** - поскольку описывается привычными манифестами Kubernetes
- **Эффективное** - так как автоматически масштабируется с минимальным ручным вмешательством

Это важный момент: автоматическое масштабирование берет на себя тяжелую ручную работу, самостоятельно регулируя ресурсы приложений, позволяя нашим командам сосредоточиться на других задачах, а не на устранении неполадок с ресурсами.

---

</details>

<details>
<summary><b>🔧Механизмы масштабирования в Kubernetes</b></summary>

---

## Два аспекта масштабирования

Окей, давай теперь поговорим о механизмах масштабирования в Kubernetes. Вообще, как это выглядит?

В глобальном масштабировании делится на два аспекта:

1. **Масштабирование кластера** - добавление рабочих узлов
2. **Масштабирование PODs** - изменение количества реплик приложений

### Общая схема двух уровней масштабирования

```
┌─────────────────────────────────────────────────────────┐
│  Уровень 1: Масштабирование кластера                    │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Cluster Autoscaler                              │   │
│  │  Добавляет/удаляет рабочие узлы (VM)              │   │
│  │  Увеличивает общую емкость кластера               │   │
│  └──────────────────────────────────────────────────┘   │
│                        │                                 │
│                        ▼                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Уровень 2: Масштабирование PODs                 │   │
│  │  HPA, VPA, KEDA                                   │   │
│  │  Добавляет/удаляет реплики приложений             │   │
│  │  Настраивает ресурсы PODs                         │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## 1. Масштабирование кластера

Во-первых, масштабирование кластера, при котором мы фактически добавляем рабочие узлы в кластер.

Обычно это будут виртуальные машины, которые выделяются по запросу из самого кластера. Далее они присоединяются к нему и берут на размещение наши PODs.

Эти рабочие узлы могут масштабироваться вверх или вниз.

### Схема масштабирования кластера

```
┌─────────────────────────────────────────────────────────┐
│  Кластер (3 узла)                                       │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Node 1: ✅                                      │   │
│  │  Node 2: ✅                                      │   │
│  │  Node 3: ✅                                      │   │
│  │                                                   │   │
│  │  Общая емкость: 300 CPU, 600GB RAM              │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼ (высокая нагрузка)
┌─────────────────────────────────────────────────────────┐
│  Cluster Autoscaler добавляет узлы                       │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Node 1: ✅                                      │   │
│  │  Node 2: ✅                                      │   │
│  │  Node 3: ✅                                      │   │
│  │  Node 4: ✅ (новый)                              │   │
│  │  Node 5: ✅ (новый)                              │   │
│  │                                                   │   │
│  │  Общая емкость: 500 CPU, 1000GB RAM              │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

### Cluster Autoscaler

Тут важное замечание: мы говорим о механизме **Cluster Autoscaler**, а не о Cluster Pod Autoscaler или CPU Cluster Autoscaler.

Cluster Autoscaler позволяет принимать и удалять рабочих участников кластера, что увеличивает общий объем ресурсов (CPU, памяти и хранения).

В свою очередь, это позволяет инструментам HPA (Horizontal Pod Autoscaler) и VPA (Vertical Pod Autoscaler) работать с PODs внутри кластера, опираясь на эти новые мощности.

Тем самым, Cluster Autoscaler занимается самим кластером, а не тем, что в кластере, и оперирует рабочими нодами.

---

## 2. Масштабирование PODs

Автоскейлеры PODs оперируют нагрузками, которые исполняются внутри нод.

Чтобы это лучше представить, перейдем с уровня кластера на уровень нода. Теперь мы погрузились на более низкий уровень виртуальной машины, который по сути является рабочая нода.

Здесь в разных пространствах имен бегут PODs разных приложений.

### Схема уровня ноды

```
┌─────────────────────────────────────────────────────────┐
│  Node: worker-1                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Namespace: default                              │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  POD: app-1                                  │ │   │
│  │  │  POD: app-2                                  │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  Namespace: production                           │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  POD: api-server                             │ │   │
│  │  │  POD: db-proxy                               │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Два пути передачи ресурсов приложению

Мы можем передать ресурсы приложению двумя путями:

1. **Добавить дополнительный POD** - то есть отдельный экземпляр приложения
2. **Добавить вычислительные ресурсы** для уже действующих PODs, позволяя этому экземпляру обрабатывать больше пользователей

### Схема двух подходов

```
┌─────────────────────────────────────────────────────────┐
│  Подход 1: Горизонтальное масштабирование (HPA)          │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Добавление реплик POD                           │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  POD 1: app (CPU: 100m)                     │ │   │
│  │  │  POD 2: app (CPU: 100m)                     │ │   │
│  │  │  POD 3: app (CPU: 100m) ← новый             │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │  ✅ Больше экземпляров = больше пропускная        │   │
│  │     способность                                   │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  Подход 2: Вертикальное масштабирование (VPA)            │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Увеличение ресурсов существующего POD            │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  POD 1: app                                  │ │   │
│  │  │  CPU: 100m → 500m (увеличено)               │ │   │
│  │  │  Memory: 128Mi → 512Mi (увеличено)          │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │  ✅ Больше ресурсов = больше производительность  │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Горизонтальный Pod Autoscaler (HPA)

Добавлением экземпляров занимается горизонтальный автоскейлер. В зависимости от нагрузки он может также их убирать.

### Как работает HPA

```
┌─────────────────────────────────────────────────────────┐
│  HPA: horizontal-pod-autoscaler                         │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Мониторит метрики (CPU, Memory, Custom)         │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Текущая нагрузка: 80% CPU                  │ │   │
│  │  │  Целевая нагрузка: 70% CPU                    │ │   │
│  │  │  Текущие реплики: 3                          │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  Решение: увеличить реплики                      │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Новые реплики: 4 (3 → 4)                  │ │   │
│  │  │  Нагрузка: 80% → 60% (снизилась)           │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Вертикальный Pod Autoscaler (VPA)

Вертикальный скейлер будет убирать менее мощные PODs и постепенно заменять их на более мощные.

---

## Пропорциональное масштабирование

Пропорциональное масштабирование будет добавлять в кластер дополнительные сервисные PODs по мере разрастания кластера.

Например, по одной реплике CoreDNS на каждые десять нод.

---

## KEDA (Kubernetes Event-Driven Autoscaling)

Принять решение о масштабировании можно основываясь на текущей нагрузке на ноды или на основе некоторых событий, например, из внешней облачной службы.

За такие события отвечает механизм **KEDA**. Он принимает внешние сигналы и масштабирует нагрузки по событию.

### Схема работы KEDA

```
┌─────────────────────────────────────────────────────────┐
│  KEDA: Event-Driven Autoscaling                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │                                                   │   │
│  │  Внешние события:                                 │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Kafka: 1000 сообщений в очереди             │ │   │
│  │  │  RabbitMQ: 500 задач                         │ │   │
│  │  │  Prometheus: метрика > threshold            │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  KEDA обрабатывает события                        │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Масштабирует PODs на основе событий         │ │   │
│  │  │  PODs: 2 → 10 (автоматически)               │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

</details>

<details>
<summary><b>🤔Зачем нужны разные стратегии?</b></summary>

---

## Два разных процесса

У тебя может возникнуть вопрос: зачем делать это таким сложным и для чего нужны все эти разные стратегии?

Это из-за того, что у нас два очень разных процесса:

### 1. Автоматическое масштабирование кластера

Это масштабирование узлов, обеспечение бесперебойной работы кластера и изменение его емкостей. Каждый из этих нод может разместить наше приложение.

### 2. Масштабирование PODs

Когда мы говорим о масштабировании PODs, мы говорим не о новых серверах для нашего кластера, а о репликах приложений, размещенных в этом кластере.

Скалирование PODs повышает доступность и эффективность приложений.

---

## Сравнение подходов

### Схема различий

```
┌─────────────────────────────────────────────────────────┐
│  Масштабирование кластера                                │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Уровень: Кластер                                │   │
│  │  Операции: Добавление/удаление узлов             │   │
│  │  Результат: Увеличение общей емкости             │   │
│  │  Время: Минуты (создание VM)                     │   │
│  │  Механизм: Cluster Autoscaler                    │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  Масштабирование PODs                                    │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Уровень: Рабочая нагрузка                       │   │
│  │  Операции: Добавление/удаление реплик            │   │
│  │  Результат: Больше экземпляров приложения        │   │
│  │  Время: Секунды (создание POD)                   │   │
│  │  Механизм: HPA, VPA, KEDA                         │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Взаимодействие механизмов

Именно поэтому у нас разные стратегии и механизмы:

- **Первая стратегия** увеличивает емкость кластера
- **Вторая** населяет эти мощности приложениями

Масштабирование PODs происходит на уровне рабочей нагрузки, а масштабирование кластера - на уровне кластера, оперируя нодами.

Они работают рука об руку, чтобы гарантировать оптимальное состояние нашей среды Kubernetes.

Тем самым происходит адаптация среды к изменениям, сохраняя экономическую эффективность, доступность ресурсов, отказоустойчивость и все то, о чем мы говорили.

### Схема совместной работы

```
┌─────────────────────────────────────────────────────────┐
│  Интегрированное масштабирование                         │
│  ┌──────────────────────────────────────────────────┐   │
│  │                                                   │   │
│  │  Высокая нагрузка на приложение                  │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  HPA: увеличивает реплики PODs               │ │   │
│  │  │  PODs: 3 → 10                               │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  Недостаточно ресурсов в кластере                 │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Cluster Autoscaler: добавляет узлы         │ │   │
│  │  │  Nodes: 3 → 5                               │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │                                                   │   │
│  │  ✅ Кластер и приложения масштабируются вместе    │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

</details>

<details>
<summary><b>📊Особенности масштабирования разных приложений</b></summary>

---

## Stateless vs Stateful приложения

Эти два подхода будут отличаться в зависимости от того, какое приложение мы масштабируем.

Это потому, что добавление дополнительных реплик хорошо подходит для PODs без сохранения состояния (stateless).

Если наше приложение stateful, например, база данных, то простое добавление реплик ему не подойдет.

Это не значит, что с ними нельзя так поступать, просто масштабирование stateful приложений требует дополнительной доводки.

### Схема различий

```
┌─────────────────────────────────────────────────────────┐
│  Stateless приложение (веб-сервер)                       │
│  ┌──────────────────────────────────────────────────┐   │
│  │  POD 1: nginx                                    │   │
│  │  POD 2: nginx                                    │   │
│  │  POD 3: nginx ← легко добавить                  │   │
│  │                                                   │   │
│  │  ✅ Простое горизонтальное масштабирование       │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  Stateful приложение (база данных)                       │
│  ┌──────────────────────────────────────────────────┐   │
│  │  POD 1: mysql (master)                          │   │
│  │  POD 2: mysql (replica)                        │   │
│  │  POD 3: mysql (replica) ← требует настройки     │   │
│  │                                                   │   │
│  │  ⚠️ Требует репликации данных                    │   │
│  │  ⚠️ Нужна настройка StatefulSet                 │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

</details>

---

## Резюме

### Преимущества автомасштабирования

1. **Экономия средств** - платим только за используемые ресурсы
2. **Доступность приложения** - автоматическая адаптация к нагрузке
3. **Эффективное использование ресурсов** - оптимальный баланс
4. **Эластичность** - адаптация к непредсказуемым изменениям
5. **Отказоустойчивость** - автоматическое восстановление
6. **Бесперебойное управление нагрузкой** - бесшовное масштабирование
7. **Простота реализации** - манифесты Kubernetes, минимальное вмешательство

### Два уровня масштабирования

1. **Масштабирование кластера** (Cluster Autoscaler)
   - Добавление/удаление рабочих узлов
   - Увеличение общей емкости кластера
   - Операции на уровне инфраструктуры

2. **Масштабирование PODs** (HPA, VPA, KEDA)
   - Добавление/удаление реплик приложений
   - Настройка ресурсов PODs
   - Операции на уровне рабочей нагрузки

### Механизмы масштабирования PODs

- **HPA (Horizontal Pod Autoscaler)** - горизонтальное масштабирование (больше реплик)
- **VPA (Vertical Pod Autoscaler)** - вертикальное масштабирование (больше ресурсов на POD)
- **KEDA** - масштабирование на основе событий
- **Пропорциональное масштабирование** - автоматическое масштабирование системных PODs

### Ключевые выводы

- **Масштабирование кластера** гарантирует, что инфраструктура соответствует поставленной задаче
- **Масштабирование PODs** гарантирует, что приложение соответствует поставленной задаче
- **Оба фактора вместе** обеспечивают кластер Kubernetes необходимой мощностью, чтобы приложения не испытывали трудностей даже при непредсказуемой нагрузке

---

Теперь должно стать понятнее, в чем важность масштабирования в Kubernetes и какие есть подходы. Это все, увидимся в следующем видео.

