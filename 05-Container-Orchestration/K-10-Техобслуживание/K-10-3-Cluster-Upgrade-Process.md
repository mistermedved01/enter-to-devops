[🏠 Главная](../../README.md) → [☸️ Container-Orchestration](../../README.md#-container-orchestration) → [🔧 K-10-Техобслуживание](../../README.md#-k-10-техобслуживание)

---

# 🔧K-10-3-Cluster-Upgrade-Process
>Процесс обновления кластера Kubernetes: совместимость версий компонентов, стратегии обновления, обновление с помощью kubeadm

---

<details>
<summary><b>📋Введение в обновление кластера</b></summary>

---

Обновление кластера Kubernetes — критическая операция, требующая понимания совместимости версий компонентов и выбора правильной стратегии обновления.

В отличие от внешних зависимостей (etcd, CoreDNS), которые имеют собственные версии, основные компоненты control plane должны следовать правилам совместимости версий.

---

</details>

<details>
<summary><b>🔗Совместимость версий компонентов</b></summary>

---

## Правило версионирования компонентов

Не все компоненты control plane должны иметь одинаковую версию. Компоненты могут быть разных релизных версий с учетом следующих правил:

### kube-apiserver как базовая версия

`kube-apiserver` является основным компонентом control plane, с которым взаимодействуют все остальные компоненты. Поэтому **все остальные компоненты не должны иметь версию выше, чем у kube-apiserver**.

### Правила совместимости

Если версия `kube-apiserver` = **X**, то:

- **kube-controller-manager** и **kube-scheduler**: могут быть версии **X** или **X-1**
- **kubelet** и **kube-proxy**: могут быть версии **X**, **X-1** или **X-2**

### Пример

Если `kube-apiserver` версии **1.20**:

```
┌─────────────────────────────────────────────────────┐
│  Компонент              |  Допустимые версии        │
├─────────────────────────┼──────────────────────────┤
│  kube-apiserver         |  1.20                     │
│  kube-controller-manager |  1.20, 1.19              │
│  kube-scheduler          |  1.20, 1.19              │
│  kubelet                 |  1.20, 1.19, 1.18        │
│  kube-proxy              |  1.20, 1.19, 1.18        │
└─────────────────────────────────────────────────────┘
```

> **⚠️ Важно:** Ни один компонент не может иметь версию выше, чем `kube-apiserver`. Например, если apiserver версии 1.20, другие компоненты не могут быть версии 1.21.

### kubectl

Утилита `kubectl` не следует тем же правилам:

- Может иметь версию выше apiserver (например, 1.21 при apiserver 1.20)
- Может иметь ту же версию, что и apiserver (1.20)
- Может иметь версию ниже apiserver (1.19)

### Преимущества гибкости версий

Допустимый перекос в версиях позволяет выполнять обновления поэтапно, обновляя компоненты по одному без необходимости обновлять весь кластер одновременно.

---

</details>

<details>
<summary><b>⏰Когда нужно обновляться</b></summary>

---

## Политика поддержки версий

Kubernetes поддерживает только **последние 3 минорные версии**.

### Пример

Если текущая последняя версия — **1.20**, то поддерживаются:

- **1.20** (текущая)
- **1.19** (предыдущая)
- **1.18** (предыдущая-предыдущая)

### Прекращение поддержки

При выпуске новой версии **1.21**:

- Поддерживаются: **1.21**, **1.20**, **1.19**
- Поддержка **1.18** прекращается

```
┌─────────────────────────────────────────────────────┐
│  До выпуска 1.21:                                   │
│  ✅ 1.20 (текущая)                                  │
│  ✅ 1.19 (предыдущая)                               │
│  ✅ 1.18 (старая)                                   │
│                                                       │
│  После выпуска 1.21:                                │
│  ✅ 1.21 (текущая)                                  │
│  ✅ 1.20 (предыдущая)                               │
│  ✅ 1.19 (старая)                                   │
│  ❌ 1.18 (поддержка прекращена)                    │
└─────────────────────────────────────────────────────┘
```

> **⚠️ Критично:** Перед выпуском новой версии необходимо обновить кластер, чтобы не остаться на неподдерживаемой версии.

---

</details>

<details>
<summary><b>📈Стратегия обновления: по одной минорной версии</b></summary>

---

## Рекомендуемый подход

**Не рекомендуется** обновлять кластер напрямую с 1.18 до 1.21. Правильный подход — обновлять по одной минорной версии за раз:

1. **1.18 → 1.19**
2. **1.19 → 1.20**
3. **1.20 → 1.21**

### Почему поэтапное обновление?

- Снижает риск ошибок
- Позволяет тестировать каждую версию
- Упрощает откат при проблемах
- Следует рекомендациям Kubernetes

### Схема обновления

```
┌─────────────────────────────────────────────────────┐
│  Текущая версия: 1.18                               │
│                                                       │
│  Шаг 1: 1.18 → 1.19                                 │
│  ├─ Обновление master                               │
│  ├─ Обновление workers                              │
│  └─ Тестирование                                    │
│                                                       │
│  Шаг 2: 1.19 → 1.20                                 │
│  ├─ Обновление master                               │
│  ├─ Обновление workers                              │
│  └─ Тестирование                                    │
│                                                       │
│  Шаг 3: 1.20 → 1.21                                 │
│  ├─ Обновление master                               │
│  ├─ Обновление workers                              │
│  └─ Тестирование                                    │
│                                                       │
│  Финальная версия: 1.21                             │
└─────────────────────────────────────────────────────┘
```

---

</details>

<details>
<summary><b>🔄Процесс обновления кластера</b></summary>

---

## Два основных этапа

Обновление кластера состоит из двух этапов:

1. **Обновление master узлов** (control plane)
2. **Обновление worker узлов**

### Этап 1: Обновление master

Во время обновления master компоненты control plane временно недоступны:

- `kube-apiserver` — недоступен
- `kube-scheduler` — недоступен
- `kube-controller-manager` — недоступен

#### Влияние на кластер

```
┌─────────────────────────────────────────────────────┐
│  Во время обновления master:                        │
│                                                       │
│  ✅ Worker узлы работают                            │
│  ✅ Pod на workers продолжают работать              │
│  ✅ Пользователи получают доступ к приложениям      │
│                                                       │
│  ❌ kubectl недоступен                              │
│  ❌ API Kubernetes недоступен                       │
│  ❌ Развертывание новых приложений невозможно        │
│  ❌ Удаление/изменение существующих невозможно       │
│  ❌ Автоматическое восстановление Pod отключено      │
└─────────────────────────────────────────────────────┘
```

> **📌 Важно:** Приложения на worker узлах продолжают работать, но управление кластером недоступно.

### Этап 2: Обновление workers

После обновления master узлы workers все еще на старой версии. Это допустимо, если версия workers не выше версии `kube-apiserver`.

---

</details>

<details>
<summary><b>🎯Стратегии обновления worker узлов</b></summary>

---

## Стратегия 1: Обновление всех узлов сразу

### Процесс

```bash
# Обновить все worker узлы одновременно
kubectl drain <node1> <node2> <node3> --ignore-daemonsets
# Обновить все узлы
# Вернуть узлы в кластер
kubectl uncordon <node1> <node2> <node3>
```

### Характеристики

- ✅ Быстрое обновление
- ❌ **Приводит к простою** — все Pod останавливаются
- ❌ Пользователи теряют доступ к приложениям
- ❌ Не рекомендуется для продакшена

### Схема

```
┌─────────────────────────────────────────────────────┐
│  До обновления:                                      │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐          │
│  │ Worker 1 │  │ Worker 2 │  │ Worker 3 │          │
│  │ 🟢 Pod   │  │ 🔴 Pod   │  │ 🟢 Pod   │          │
│  └──────────┘  └──────────┘  └──────────┘          │
│                                                       │
│  Обновление всех узлов → Простой                    │
│                                                       │
│  После обновления:                                    │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐          │
│  │ Worker 1 │  │ Worker 2 │  │ Worker 3 │          │
│  │ (новые)  │  │ (новые)  │  │ (новые)  │          │
│  └──────────┘  └──────────┘  └──────────┘          │
└─────────────────────────────────────────────────────┘
```

---

## Стратегия 2: Обновление по одному узлу

### Процесс

Обновление узлов последовательно, по одному за раз.

### Характеристики

- ✅ **Без простоя** — приложения остаются доступными
- ✅ Безопасное обновление
- ✅ Рекомендуется для продакшена
- ⏱️ Занимает больше времени

### Схема

```
┌─────────────────────────────────────────────────────┐
│  Шаг 1: Обновление Worker 1                         │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐          │
│  │ Worker 1 │  │ Worker 2 │  │ Worker 3 │          │
│  │ (drained)│  │ 🔴 Pod   │  │ 🟢 Pod   │          │
│  │          │  │ 🟢 Pod   │  │ 🔴 Pod   │          │
│  └──────────┘  └──────────┘  └──────────┘          │
│                                                       │
│  Шаг 2: Обновление Worker 2                         │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐          │
│  │ Worker 1 │  │ Worker 2 │  │ Worker 3 │          │
│  │ 🟢 Pod   │  │ (drained)│  │ 🔴 Pod   │          │
│  │ 🔴 Pod   │  │          │  │ 🟢 Pod   │          │
│  └──────────┘  └──────────┘  └──────────┘          │
│                                                       │
│  Шаг 3: Обновление Worker 3                         │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐          │
│  │ Worker 1 │  │ Worker 2 │  │ Worker 3 │          │
│  │ 🟢 Pod   │  │ 🟢 Pod   │  │ (drained)│          │
│  │ 🔴 Pod   │  │ 🔴 Pod   │  │          │          │
│  └──────────┘  └──────────┘  └──────────┘          │
│                                                       │
│  Все узлы обновлены без простоя                      │
└─────────────────────────────────────────────────────┘
```

### Процедура для каждого узла

1. `kubectl drain <node>` — переместить Pod на другие узлы
2. Обновить компоненты узла
3. `kubectl uncordon <node>` — вернуть узел в кластер
4. Повторить для следующего узла

---

## Стратегия 3: Добавление новых узлов

### Процесс

Добавление новых узлов с новой версией и постепенное удаление старых.

### Характеристики

- ✅ **Без простоя**
- ✅ Удобно в облачных средах
- ✅ Минимальный риск
- ⏱️ Требует дополнительных ресурсов

### Схема

```
┌─────────────────────────────────────────────────────┐
│  Шаг 1: Добавить новый узел с версией 1.19          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐          │
│  │ Worker 1 │  │ Worker 2 │  │ Worker 3 │          │
│  │ (1.18)   │  │ (1.18)   │  │ (1.18)   │          │
│  └──────────┘  └──────────┘  └──────────┘          │
│                                                       │
│  ┌──────────┐                                        │
│  │ Worker 4 │                                        │
│  │ (1.19)   │ ← новый узел                          │
│  └──────────┘                                        │
│                                                       │
│  Шаг 2: Переместить нагрузку на новый узел          │
│  Шаг 3: Удалить старый узел                         │
│  Повторить для всех узлов                           │
└─────────────────────────────────────────────────────┘
```

### Процедура

1. Создать новый узел с новой версией
2. Присоединить узел к кластеру
3. Переместить Pod на новый узел (`kubectl drain` старого узла)
4. Удалить старый узел
5. Повторить для остальных узлов

---

</details>

<details>
<summary><b>🛠️Обновление с помощью kubeadm</b></summary>

---

## Подготовка к обновлению

### Проверка текущих версий

```bash
# Версии узлов (показывает версию kubelet)
kubectl get nodes

# Версия kubeadm
kubeadm version

# Версия компонентов control plane
kubectl get --raw /version
```

### Обновление kubeadm

Перед обновлением кластера необходимо обновить сам инструмент `kubeadm` до целевой версии:

```bash
# Обновить кэш пакетов
apt-get update

# Установить конкретную версию kubeadm
apt-get install -y kubeadm=1.19.8-00
```

> **⚠️ Важно:** Обновляйте только на одну минорную версию за раз. Если текущая версия 1.18, обновляйте до 1.19, а не до 1.20.

---

## Планирование обновления

### Команда upgrade plan

Команда `kubeadm upgrade plan` предоставляет информацию о текущем состоянии и доступных обновлениях:

```bash
kubeadm upgrade plan
```

### Вывод команды включает:

- Текущую версию кластера
- Версию инструмента kubeadm
- Последнюю стабильную версию Kubernetes
- Список компонентов control plane с их версиями
- Версии, до которых можно обновить каждый компонент
- Команду для выполнения обновления
- Напоминание об обновлении kubelet на каждом узле

### Пример вывода

```
[upgrade/config] Making sure the configuration is correct:
[preflight] Running pre-flight checks.
[upgrade] Fetching available versions to upgrade to
[upgrade/versions] Cluster version: v1.18.0
[upgrade/versions] kubeadm version: v1.19.8
[upgrade/versions] Latest stable version: v1.20.4
[upgrade/versions] Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply':
COMPONENT   CURRENT   AVAILABLE
kubelet     1.18.0    1.19.8
kubectl     1.18.0    1.19.8
[upgrade] You can now apply the upgrade by executing the following command:
        kubeadm upgrade apply v1.19.8
```

---

## Обновление master узла

### Шаг 1: Обновление control plane

```bash
# Применить обновление до версии 1.19.8
kubeadm upgrade apply v1.19.8
```

Команда выполняет:

- Загрузку необходимых образов
- Обновление компонентов control plane
- Проверку совместимости

### Шаг 2: Обновление kubelet и kubectl

После обновления control plane необходимо обновить `kubelet` и `kubectl` на master узле:

```bash
# Обновить kubelet и kubectl
apt-get upgrade -y kubelet=1.19.8-00 kubectl=1.19.8-00 --allow-change-held-packages

# Перезапустить kubelet (если не перезапустился автоматически)
systemctl restart kubelet
```

### Проверка обновления master

```bash
# Проверить версию узла
kubectl get nodes

# Должна отображаться версия 1.19.8
```

> **📌 Примечание:** Команда `kubectl get nodes` показывает версию `kubelet`, а не версию компонентов control plane. Для проверки версии control plane используйте `kubectl get --raw /version`.

---

## Обновление worker узлов

### Процедура для каждого worker узла

#### Шаг 1: Подготовка узла

```bash
# Переместить Pod на другие узлы и заблокировать планирование
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data
```

#### Шаг 2: Обновление kubeadm

```bash
# На worker узле
apt-get update
apt-get install -y kubeadm=1.19.8-00
```

#### Шаг 3: Обновление конфигурации узла

```bash
# Обновить конфигурацию узла для новой версии
kubeadm upgrade node
```

#### Шаг 4: Обновление kubelet и kubectl

```bash
# Обновить kubelet и kubectl
apt-get upgrade -y kubelet=1.19.8-00 kubectl=1.19.8-00 --allow-change-held-packages

# Перезапустить kubelet
systemctl restart kubelet
```

> **⚠️ Важно:** Если версия kubelet оказалась выше, чем версия apiserver, необходимо выполнить downgrade:
>
> ```bash
> apt-get upgrade -y kubelet=1.19.8-00 kubectl=1.19.8-00 --allow-downgrades
> ```

#### Шаг 5: Возврат узла в кластер

```bash
# Снять блокировку планирования
kubectl uncordon <node-name>
```

> **📌 Важно:** После `uncordon` Pod не возвращаются автоматически на узел. Они остаются на узлах, куда были перемещены. Новые Pod или пересозданные Pod могут быть запланированы на обновленный узел.

#### Шаг 6: Повторить для следующего узла

Повторить процедуру для каждого worker узла последовательно.

---

</details>

<details>
<summary><b>📝Практический пример: обновление с 1.18 до 1.19</b></summary>

---

## Сценарий

Кластер состоит из:
- 1 master узел (версия 1.18)
- 2 worker узла (версия 1.18)

Необходимо обновить кластер до версии 1.19.

---

## Обновление master узла

### 1. Проверка текущих версий

```bash
# Версии узлов
kubectl get nodes

# Версия kubeadm
kubeadm version
```

### 2. Обновление kubeadm

```bash
apt-get update
apt-get install -y kubeadm=1.19.8-00
```

### 3. Планирование обновления

```bash
kubeadm upgrade plan
```

### 4. Применение обновления

```bash
kubeadm upgrade apply v1.19.8
```

### 5. Обновление kubelet и kubectl

```bash
apt-get upgrade -y kubelet=1.19.8-00 kubectl=1.19.8-00 --allow-change-held-packages
systemctl restart kubelet
```

### 6. Проверка

```bash
kubectl get nodes
# Master должен показывать версию 1.19.8
```

---

## Обновление worker узлов

### Worker Node 1

```bash
# 1. Подготовка узла
kubectl drain node01 --ignore-daemonsets --delete-emptydir-data

# 2. На узле node01: обновление kubeadm
apt-get update
apt-get install -y kubeadm=1.19.8-00

# 3. Обновление конфигурации
kubeadm upgrade node

# 4. Обновление kubelet и kubectl
apt-get upgrade -y kubelet=1.19.8-00 kubectl=1.19.8-00 --allow-change-held-packages
systemctl restart kubelet

# 5. Возврат узла в кластер
kubectl uncordon node01
```

### Worker Node 2

```bash
# Повторить те же шаги для node02
kubectl drain node02 --ignore-daemonsets --delete-emptydir-data
# ... (те же команды на узле node02)
kubectl uncordon node02
```

### Финальная проверка

```bash
# Все узлы должны показывать версию 1.19.8
kubectl get nodes
```

---

</details>

<details>
<summary><b>⚠️Важные замечания</b></summary>

---

## Особенности версионирования

### kubectl get nodes показывает версию kubelet

Команда `kubectl get nodes` отображает версию `kubelet`, зарегистрированного в apiserver, а не версию компонентов control plane.

Для проверки версии control plane используйте:

```bash
kubectl get --raw /version
```

### kubelet на master узле

В кластерах, развернутых с помощью `kubeadm`, `kubelet` установлен на master узле для запуска контейнеров компонентов control plane.

В кластерах, настроенных с нуля, `kubelet` может отсутствовать на master узле.

### Pod не возвращаются автоматически

После выполнения `kubectl uncordon` Pod не возвращаются автоматически на обновленный узел. Они остаются на узлах, куда были перемещены во время `drain`.

Новые Pod или пересозданные Pod могут быть запланированы на обновленный узел.

---

</details>

---

## Связанные темы

- **[K-10-1-OS-Upgrades](K-10-1-OS-Upgrades.md)** — обновление ОС узлов
- **[K-10-2-K8s-Software-Versions](K-10-2-K8s-Software-Versions.md)** — версионирование Kubernetes
- **[K-10-3-Cluster-Upgrade-Process](K-10-3-Cluster-Upgrade-Process.md)** — процесс обновления кластера **← Текущая тема**
- **[K-10-4-Backup-and-Restore-Methods](K-10-4-Backup-and-Restore-Methods.md)** — методы резервного копирования и восстановления

---

## Что дальше?

В следующей теме [K-10-4-Backup-and-Restore-Methods](K-10-4-Backup-and-Restore-Methods.md) мы рассмотрим методы резервного копирования и восстановления кластера Kubernetes, включая резервное копирование через kube-api, резервное копирование etcd и восстановление кластера из резервных копий.

---