[🏠 Главная](../../README.md) → [☸️ Container-Orchestration](../../README.md#-container-orchestration) → [💾 K-12-Хранение](../../README.md#-k-12-хранение)

---

# 💾K-12-5-Volumes
>Volumes в Kubernetes: временная природа PODs, монтирование томов, типы томов (hostPath, AWS EBS, NFS и др.), проблемы многоузловых кластеров

**📍 Текущая тема**

---

<details>
<summary><b>📚Введение: Volumes в Kubernetes</b></summary>

---

## Связь с Docker

Прежде чем перейти к постоянным томам (Persistent Volumes), рассмотрим базовые volumes в Kubernetes.

Для понимания контекста начнем с томов в Docker.

---

## Временная природа контейнеров

Контейнеры Docker должны быть временными по своей природе, что означает, что они предназначены для работы только в течение небольшого периода времени.

Они вызываются, когда требуется обработать данные, и уничтожаются после завершения.

То же самое верно и для данных в контейнере: данные уничтожаются вместе с контейнером.

---

## Решение: Volumes в Docker

Для сохранения данных, обрабатываемых контейнерами, мы присоединяем тома к контейнерам при их создании.

Эти данные, обрабатываемые контейнером, теперь помещаются в volume, тем самым сохраняясь навсегда.

Когда контейнер будет удален, сгенерированные или обработанные им данные останутся.

---

## Volumes в Kubernetes

Как и в Docker, POD, созданный в Kubernetes, временный по своей природе.

Когда создается POD для обработки данных, а затем удаляется, обрабатываемые им данные также удаляются.

Для сохранения мы прикрепляем volume к POD.

Данные, сгенерированные POD, теперь хранятся в томе, и даже после удаления POD данные остаются.

### Сравнение Docker и Kubernetes

```
┌─────────────────────────────────────────────────────────┐
│  Docker                                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Контейнер (временный)                           │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Данные (удаляются с контейнером)          │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Volume (сохраняются)                       │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
│                        │                                 │
│                        ▼                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Kubernetes                                      │   │
│  │  ┌──────────────────────────────────────────────────┐ │
│  │  │  POD (временный)                                │ │
│  │  │  ┌─────────────────────────────────────────────┐ │ │
│  │  │  │  Данные (удаляются с POD)                  │ │ │
│  │  │  └─────────────────────────────────────────────┘ │ │
│  │  │  ┌─────────────────────────────────────────────┐ │ │
│  │  │  │  Volume (сохраняются)                       │ │ │
│  │  │  └─────────────────────────────────────────────┘ │ │
│  │  └──────────────────────────────────────────────────┘ │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

</details>

<details>
<summary><b>🔧Простой пример использования Volumes</b></summary>

---

## Сценарий

Рассмотрим простую реализацию volumes.

У нас есть кластер Kubernetes с одним узлом.

Мы создаем простой POD, который генерирует случайное число от 1 до 100 и записывает его в файл по адресу `/opt/number.out`, на этом его работа заканчивается и POD удаляется.

При удалении POD данные также будут удалены.

---

## Создание Volume

Чтобы сохранить номер, сгенерированный POD, мы создаем volume, и этому volume требуется хранилище.

При создании тома мы можем настроить его хранилище разными способами.

Мы немного рассмотрим различные параметры, а пока просто настроим его для использования каталога на хосте.

### Пример манифеста POD с volume

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: random-number-generator
spec:
  containers:
  - name: number-generator
    image: alpine
    command: ["sh", "-c", "echo $((RANDOM % 100 + 1)) > /opt/number.out"]
    volumeMounts:
    - name: data-volume
      mountPath: /opt
  volumes:
  - name: data-volume
    hostPath:
      path: /data
      type: DirectoryOrCreate
```

В этом случае мы указываем путь `/data` в поле `hostPath`.

Таким образом, любые файлы, созданные в этом volume, будут храниться в каталоге `/data` на этом узле.

---

## Монтирование Volume

После создания volume для доступа к нему из контейнера мы монтируем volume в каталог внутри контейнера.

Мы используем поле `volumeMounts` в каждом контейнере для монтирования тома `data-volume` в каталог `/opt` внутри контейнера.

### Схема монтирования volume

```
┌─────────────────────────────────────────────────────────┐
│  Kubernetes Node                                         │
│  ┌──────────────────────────────────────────────────┐   │
│  │  /data/ (на хосте)                               │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  number.out (сохраняется)                   │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
│                        │                                 │
│                        │ Монтирование                    │
│                        ▼                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  POD: random-number-generator                     │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Container: number-generator                │ │   │
│  │  │  ┌───────────────────────────────────────┐ │ │   │
│  │  │  │  /opt/ (смонтированный volume)        │ │ │   │
│  │  │  │  ┌───────────────────────────────────┐ │ │ │   │
│  │  │  │  │  number.out                       │ │ │ │   │
│  │  │  │  └───────────────────────────────────┘ │ │ │   │
│  │  │  └───────────────────────────────────────┘ │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Как это работает

Теперь случайное число будет записано в директорию `/opt`, смонтированную внутри контейнера.

И этот каталог связан через том `data-volume` с каталогом `/data` на хосте.

То есть эта папка `/opt` контейнера фактически является папкой `/data` файловой системы ноды.

---

## Сохранение данных

Когда POD удаляется, файл со случайным номером остается в папке на хосте.

Ведь вместе с POD удалилась связь между каталогом `/opt` и `/data`, но сам каталог `/data` никто не удалял.

---

</details>

<details>
<summary><b>⚠️Проблема: hostPath в многоузловых кластерах</b></summary>

---

## Ограничения hostPath

Мы просто использовали параметр `hostPath` для настройки каталога, и этим выделили место на хосте для размещения тома.

И это отлично работает на одном узле.

Но что, если кластер многоузловой?

---

## Проблема с несколькими узлами

Такой подход будет не рекомендован.

Это связано с тем, что PODs будут использовать каталог `/data` на всех нодах, но будут полагать, что это один и тот же каталог.

Следовательно, и ожидать, что все данные, положенные туда, сохранятся.

Но это не так, будет мозаика из файлов, созданных отработавшими PODs, и разбросанная по папкам `/data` всех нодах кластера.

Потому что эти volumes создавались на каждой ноде, где запускался POD.

### Схема проблемы hostPath в многоузловом кластере

```
┌─────────────────────────────────────────────────────────┐
│  Многоузловой кластер Kubernetes                        │
│                                                           │
│  ┌──────────────────┐        ┌──────────────────┐      │
│  │  Node 1          │        │  Node 2          │      │
│  │  ┌────────────┐  │        │  ┌────────────┐  │      │
│  │  │ /data/     │  │        │  │ /data/     │  │      │
│  │  │ file1.out  │  │        │  │ file2.out  │  │      │
│  │  └────────────┘  │        │  └────────────┘  │      │
│  │        │          │        │        │          │      │
│  │        ▼          │        │        ▼          │      │
│  │  ┌────────────┐  │        │  ┌────────────┐  │      │
│  │  │ POD 1      │  │        │  │ POD 2      │  │      │
│  │  │ (hostPath) │  │        │  │ (hostPath) │  │      │
│  │  └────────────┘  │        │  └────────────┘  │      │
│  └──────────────────┘        └──────────────────┘      │
│                                                           │
│  ❌ Проблема: Каждый POD видит только свой /data        │
│  ❌ Данные разбросаны по разным узлам                    │
│  ❌ Нет единого хранилища                                │
└─────────────────────────────────────────────────────────┘
```

---

## Решение: внешнее кластерное хранилище

Это можно изменить, используя какое-нибудь решение для внешнего кластерного хранилища с репликацией.

### Схема решения с внешним хранилищем

```
┌─────────────────────────────────────────────────────────┐
│  Многоузловой кластер Kubernetes                        │
│                                                           │
│  ┌──────────────────┐        ┌──────────────────┐      │
│  │  Node 1          │        │  Node 2          │      │
│  │  ┌────────────┐  │        │  ┌────────────┐  │      │
│  │  │ POD 1      │  │        │  │ POD 2      │  │      │
│  │  └─────┬──────┘  │        │  └─────┬──────┘  │      │
│  └────────┼─────────┘        └────────┼─────────┘      │
│           │                           │                 │
│           └───────────┬───────────────┘                 │
│                       ▼                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Внешнее кластерное хранилище                     │   │
│  │  (NFS, Ceph, GlusterFS, AWS EBS и др.)          │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Единое хранилище с репликацией             │ │   │
│  │  │  - file1.out                                │ │   │
│  │  │  - file2.out                                │ │   │
│  │  │  - Все данные доступны всем PODs           │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
│                                                           │
│  ✅ Решение: Единое хранилище для всех узлов            │
│  ✅ Данные доступны независимо от узла                  │
└─────────────────────────────────────────────────────────┘
```

---

</details>

<details>
<summary><b>💾Типы Volumes в Kubernetes</b></summary>

---

## Поддерживаемые типы хранилищ

Kubernetes поддерживает несколько типов стандартных решений для хранения, таких как:

### Сетевые хранилища

- **NFS** — Network File System
- **CephFS** — распределенная файловая система Ceph
- **GlusterFS** — распределенная файловая система
- **ScaleIO** — программно-определяемое хранилище
- **Flocker** — оркестрация томов для контейнеров
- **FibreChannel** — SAN хранилище

### Облачные решения

- **AWS EBS** — Elastic Block Store от Amazon
- **AWS EFS** — Elastic File System от Amazon
- **Azure Disk** — управляемые диски Azure
- **Azure File** — файловое хранилище Azure
- **Google Persistent Disk** — постоянные диски GCP

### Локальные хранилища

- **hostPath** — монтирование директории хоста (только для разработки/тестирования)
- **emptyDir** — временное хранилище, существующее только в течение жизни POD

---

## Пример: AWS EBS Volume

Например, чтобы настроить том AWS Elastic Block Store в качестве хранилища или тома, мы заменяем в volumes поле `hostPath` на `awsElasticBlockStore`, туда добавляем параметр `volumeID` и `fsType`.

### Пример манифеста с AWS EBS

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    - name: data-volume
      mountPath: /data
  volumes:
  - name: data-volume
    awsElasticBlockStore:
      volumeID: vol-12345678
      fsType: ext4
```

Теперь этот том будет использовать хранилище, находящееся в AWS EBS.

Для нормальной работы необходимо настроить доступ (IAM роли, credentials).

### Схема работы с AWS EBS

```
┌─────────────────────────────────────────────────────────┐
│  Kubernetes Cluster (AWS)                                │
│  ┌──────────────────────────────────────────────────┐   │
│  │  Node                                            │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  POD: my-app                                │ │   │
│  │  │  ┌───────────────────────────────────────┐ │ │   │
│  │  │  │  Container: app                        │ │ │   │
│  │  │  │  /data/ (смонтированный том)          │ │ │   │
│  │  │  └───────────────────────────────────────┘ │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
│                        │                                 │
│                        │ Монтирование                    │
│                        ▼                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  AWS EBS Volume (vol-12345678)                  │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  Данные (сохраняются в облаке)             │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Пример: NFS Volume

Для использования NFS хранилища:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    - name: data-volume
      mountPath: /data
  volumes:
  - name: data-volume
    nfs:
      server: nfs-server.example.com
      path: /exports/data
```

### Схема работы с NFS

```
┌─────────────────────────────────────────────────────────┐
│  Kubernetes Cluster                                      │
│  ┌──────────────────┐        ┌──────────────────┐      │
│  │  Node 1          │        │  Node 2          │      │
│  │  ┌────────────┐  │        │  ┌────────────┐  │      │
│  │  │ POD 1      │  │        │  │ POD 2      │  │      │
│  │  │ (NFS)      │  │        │  │ (NFS)      │  │      │
│  │  └─────┬──────┘  │        │  └─────┬──────┘  │      │
│  └────────┼─────────┘        └────────┼─────────┘      │
│           │                           │                 │
│           └───────────┬───────────────┘                 │
│                       │ NFS Protocol                     │
│                       ▼                                 │
│  ┌──────────────────────────────────────────────────┐   │
│  │  NFS Server                                       │   │
│  │  ┌─────────────────────────────────────────────┐ │   │
│  │  │  /exports/data/                            │ │   │
│  │  │  (единое хранилище для всех PODs)          │ │   │
│  │  └─────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## Сравнение типов volumes

| Тип Volume | Использование | Доступность | Рекомендации |
|-----------|--------------|-------------|--------------|
| hostPath | Локальная разработка | Только на одном узле | Не использовать в production |
| emptyDir | Временные данные | В пределах POD | Для кэша, временных файлов |
| NFS | Сетевые хранилища | Все узлы | Для общих данных |
| AWS EBS | Облачное хранилище | Один узел | Для stateful приложений |
| AWS EFS | Облачное файловое хранилище | Все узлы | Для общих данных в AWS |
| Azure Disk | Облачное хранилище Azure | Один узел | Для stateful приложений в Azure |
| GCP Persistent Disk | Облачное хранилище GCP | Один узел | Для stateful приложений в GCP |

---

</details>

<details>
<summary><b>📋Структура определения Volume</b></summary>

---

## Компоненты определения Volume

Volume в Kubernetes состоит из двух частей:

1. **Определение volume** в секции `volumes` спецификации POD
2. **Монтирование volume** в секции `volumeMounts` контейнера

### Полный пример

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: nginx
    volumeMounts:
    - name: my-volume
      mountPath: /data
      readOnly: false  # опционально
  volumes:
  - name: my-volume
    hostPath:
      path: /data
      type: DirectoryOrCreate
```

---

## Поля volumeMounts

- **name** — имя volume, определенного в секции `volumes`
- **mountPath** — путь внутри контейнера, куда монтируется volume
- **readOnly** — монтировать volume только для чтения (по умолчанию `false`)
- **subPath** — монтировать поддиректорию volume вместо всего volume

---

## Поля volumes

- **name** — уникальное имя volume в рамках POD
- **type** — тип volume (hostPath, nfs, awsElasticBlockStore и т.д.)
- **type-specific fields** — параметры, специфичные для типа volume

---

</details>

<details>
<summary><b>🔐Настройка доступа к облачным хранилищам</b></summary>

---

## Требования для облачных volumes

Для нормальной работы с облачными volumes (AWS EBS, Azure Disk, GCP Persistent Disk) необходимо настроить доступ.

### AWS EBS

Для работы с AWS EBS требуется:

- **IAM роли** — роль с правами на создание и управление EBS volumes
- **Instance Profile** — привязка IAM роли к EC2 инстансу
- **Регион** — volume должен находиться в том же регионе, что и кластер

### Azure Disk

Для работы с Azure Disk требуется:

- **Service Principal** — учетные данные для доступа к Azure
- **Resource Group** — группа ресурсов Azure
- **Storage Account** — учетная запись хранения (для некоторых типов)

### GCP Persistent Disk

Для работы с GCP Persistent Disk требуется:

- **Service Account** — сервисный аккаунт с правами на диски
- **Compute Engine API** — включенный API
- **Zone** — зона, где находится диск

---

## Безопасность

Важно правильно настроить права доступа, чтобы:

- Минимизировать права доступа (принцип наименьших привилегий)
- Использовать IAM роли вместо статических ключей
- Регулярно обновлять credentials
- Мониторить использование хранилища

---

</details>

---

## Резюме

### Временная природа PODs

- PODs в Kubernetes временны по своей природе
- Данные в POD удаляются вместе с POD
- Для сохранения данных используются volumes

### Volumes в Kubernetes

- Volumes позволяют сохранять данные после удаления POD
- Volume определяется в секции `volumes` спецификации POD
- Volume монтируется в контейнер через `volumeMounts`

### Типы Volumes

- **hostPath** — локальное хранилище (только для разработки)
- **emptyDir** — временное хранилище в пределах POD
- **NFS, CephFS, GlusterFS** — сетевые хранилища
- **AWS EBS, Azure Disk, GCP Disk** — облачные хранилища

### Проблемы hostPath

- hostPath работает только на одном узле
- В многоузловых кластерах данные разбросаны по узлам
- Необходимо использовать внешнее кластерное хранилище

### Настройка доступа

- Для облачных volumes требуется настройка IAM/Service Accounts
- Важно правильно настроить права доступа
- Использовать принцип наименьших привилегий

---

## Связанные темы

- **[K-12-1-Enter-Container-Storage](K-12-1-Enter-Container-Storage.md)** — введение в концепции хранения в Docker
- **[K-12-2-Storage-in-Docker](K-12-2-Storage-in-Docker.md)** — volumes в Docker
- **[K-12-3-Volume-Driver-Plugins-in-Docker](K-12-3-Volume-Driver-Plugins-in-Docker.md)** — volume driver plugins
- **[K-12-4-CSI](K-12-4-CSI.md)** — Container Storage Interface
- **[K-12-5-Volumes](K-12-5-Volumes.md)** — volumes в Kubernetes, типы volumes и их использование **← Текущая тема**
- **[K-12-6-Persistent-Volumes](K-12-6-Persistent-Volumes.md)** — Persistent Volumes, централизованное управление хранилищем
- **[K-12-7-Persistent-Volume-Claims](K-12-7-Persistent-Volume-Claims.md)** — Persistent Volume Claims, запросы на хранилище

---

## Что дальше?

В следующей теме [K-12-6-Persistent-Volumes](K-12-6-Persistent-Volumes.md) мы рассмотрим PersistentVolumes (PV) — более продвинутый механизм Kubernetes для работы с постоянным хранилищем, который решает проблемы, связанные с прямым использованием volumes в POD определениях.

---
